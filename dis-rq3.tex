
\section{Result Discussion RQ3}
For the third and final research question, the objective was to assess how the AI generated emotion labels obtained through the speech-based and text-based emotion recognition would compare to the self-reported emotions provided by the interviewees.

In examining the alignment with the speech-based emotion labels from Hume AI and the text-based emotion labels from NLP Cloud with the self-assessed emotion scores, insightful findings revealed some levels of alignment dependent on both the model and emotion.

Figure~\ref{fig:comp-bar-rq3-all} builds on figure~\ref{fig:rq2_sent_grouped_bar}, discussed for RQ2. Presenting mean emotion scores for Hume AI and NLP Cloud and a third measurement, figure~\ref{fig:comp-bar-rq3-all} also introduces the self-assessed emotion scores.
Across the entire dataset, joy emerged as the emotion with the highest average scores for the positive recordings when it came to the self-assessed emotion scores, although NLP Cloud rated joy much higher than both the other modalities. This could be explained by the model may interpreting language as very joyful even though the tone was more neutral. This could be explained by the spontaneous interview format in a calm setting, as this format may not encourage expressively conveying these emotions.

Still examining the positive recordings, surprise presented almost identical scores for the self-assessed scores in comparison to NLP Cloud. For all other emotions (anger, sadness and fear) the participants of the interviews rated their emotions almost an average between the two models, with the scores not being quite as high as Hume AI, and not as low as NLP Cloud. Hume AI estimated anger substantially higher than NLP Cloud and somewhat higher than the interviewees themselves, which may be due to misinterpreted signs of anger for example from pitch and intensity during the interviews.
These results suggest that the only emotions detected well here compared to the self-assessed scores, was surprise, whereas the self-scores landed on a middle ground between the two models for all other emotions in the positive oriented interviews.
In the negatively oriented interviews, both fear and surprise were fairly evenly rated across all three modalities, with the self-assessed being the highest rated in both emotions.
The ratings for anger were high for all sources as well and fairly evenly matched between Hume and the self-assessed scores, while NLP Cloud rated anger even higher. The higher rating by NLP Cloud was likely due to the context of negative wording in the negative interviews forwarding the emotions more than was both felt by the participants and detected trough the voice.
For joy and sadness, NLP Cloud scored substantially closer scores to the self-assessed emotion scores compared to Hume AI. This can be explained by the context of the words matching the emotions in the interviews better, suggesting the text-based model might have been better at capturing sad emotions from the vocal recordings. Hume may not have picked up the cues for sadness in the same capacity, likely due to the low expressions of sadness during the interviews. This may further reflect a limitation in emotion recognition from spontaneous speech, which also has been highlighted in earlier research. Research done by (källa****cao 2015****), found even advanced ranking-based classifiers which had outperformed traditional models, to struggle with neutrality in spontaneous speech (källa****cao 2015****).
Further analysis for the positive clips showed Hume AI rated the emotion joy extremely high in comparison to the two other modalities. This further confirms what was earlier explained in the discussion for RQ2 ~\ref{subsec:RQ2interpretation}, that Hume AI may have incorrectly interpreted certain vocal cues as joy, for example nervous laughter or sarcasm, which could be difficult for a speech-based AI to recognize.

Overall for the sentiment-based comparisons, the negative recordings showed a better alignment for all three modalities. For both the positive and negatively oriented recordings, the two models performed better for some emotions as the text-based AI NLP Cloud seemingly captured the context for each interview more effectively for some emotions than the speech-based model and vice versa. This underscores the limitations of relying exclusively on either speech-based or text-based emotion recognition, as the different models capture different emotions with varying success. Using both models in comparison to the self-assessed scores gives a wider understanding of the performance for the text-based versus speech-based emotion recognition model and their different strengths and weaknesses. This aligns with earlier research which also have concluded that using more than one approach results in a better performance than only relying on an individual source (källa****cao 2015****).

For the correlation analyses between all recordings for Hume AI and the self-assessed emotion scores no significant correlations were found for any emotions except for anger (r = 0.359, p = 0.043) and joy (r = 0.334, p = 0.062), although joy did not show a statistically significant p-value. 
When examining the positive recordings and the negative recordings individually for the correlation analysis, no significant correlations were found for any emotions, although the positive recordings showed moderate positive trends for anger and joy. Although these emotions did not reach any significant correlations, the moderate r-values suggests a possible relationship that may be of interest to explore in the future with a lager dataset or different methods, as the lack of statistically significant correlations indicated that the emotions captured in the interviews do not align closely with those in Hume AI. 

For the correlation analyses done between NLP Cloud and the self-assessed emotion scores strong significant correlations were found over the full dataset for joy, anger, sadness and fear, with only surprise being poorly detected.
For the positive recordings joy and fear were the only emotions showing high correlation, whereas for the negative recordings only fear was detected with significance. Over both the positive and negative recordings, surprise was poorly detected with low correlations and high p-values suggesting the model struggled with the interpretation with the emotion surprise, possibly as a consequence of the complexity of the emotion and the interview format which may not have presented strong feelings of surprise.

While NLP Cloud showed stronger correlations with the self-reported emotions overall compared to the Hume AI model, these results show that the model performs inconsistently across the different contexts (negative and positive), suggesting that a more consistent recognition of emotions may demand more modalities for better accuracy. These results also point to the fact that surprise remains a complex emotion with more challenges to capture from the data used in this study, although there are additional reasons as to this challenge. In the self-evaluation segment of the interviews, multiple participants expressed certain confusion regarding the assessment of the emotion surprise. A large part of the interviews consisted of describing past emotional experiences which may have reduced the intensity of surprise. Typically, surprise is expressed as an immediate reaction to unexpected events and it’s unlikely that the interviewees are able to genuinely experience the same surprise felt in the original moment of the memory. This provides a possible explanation for why both AI models overall detected low levels of surprise, while an acted dataset could present higher correlations for this emotion. As stated in earlier research, acted speech is an amplification of emotions and spontaneous speech lacks the level of intensity to be distinguished from different emotions (källa****Chakr 2016****).

For the statistical analysis and effect sizes where the paired t-tests are presented with the Cohen’s d to compare Hume AI with the self-assessed scores, the results showed to be consistent with earlier findings, further giving grounds to this discussion. 
The full dataset showed Hume to have a moderate tendency for overestimation of the emotion anger in comparison to what the participants of the interviews had reported themselves, which remains true for the positive recordings where anger was very highly detected by Hume. The full dataset also showed Hume to underestimate surprise compared to the self-assessed scores. This further confirms surprise is a difficult and complex emotion to detect and validates conclusions from earlier research stating that neutrality is difficult for a model to deal with (källa****cao 2015****). It is possible the neutrality of the speech often coming across in a spontaneous interview format may have been one of the reasons as to why emotions like surprise were detected at low levels.
In the positive recordings the statistical analysis confirmed Hume overestimated anger, sadness and fear, while also underestimating joy. 
For the negative recordings, Hume instead predicted higher levels of joy and less for sadness. These results point to the fact that this speech-based emotion recognition model may not be capable of detecting subtle emotions and struggles without the textual context as some vocal cues seems to have been misinterpreted.

Where the comparison for NLP Cloud and the self-assessed scores was examined with the paired t-tests and the Cohen’s d, the findings showed that NLP overestimated joy and underestimated fear for the entirety of the dataset.
For the positive recordings, NLP rated anger, sadness and fear considerably low, while joy was rated high, and for the negative recordings, no significant differences were found, which further confirms a closer alignment for NLP Cloud and the self-assessed scores in the negative contexts as earlier discussed in this chapter.

In the cases of where the alignment for the models and self-assessed scores did not align as well, further explanations can be drawn from earlier research stating sentiment do not inevitably display themselves in expressions or behaviors (källa**** Soleymani2017****). In many cases both Hume AI or NLP Cloud overestimated or underestimated scores compared to the self-assessed values, likely because of vocal expressions not always aligning with the internal affective states as sentiment is not always fully articulated. 
