
\section{Result Discussion RQ2}
For the second research question in this thesis the aim was to investigate whether we could understand the emotions from textual content of the speech, with the same data as in RQ1. This was achieved by transcribing the vocal recordings and analyzing them using NLP Cloudâ€™s emotion recognition to detect emotions in the textual content of the speech.

\subsection{Interpretation of Results}
\subsection{RQ2: Speech-based AI vs Text-based AI}
In the comparison between the speech-based emotion recognition model, Hume AI, and the text-based emotion recognition model NLP Cloud, the system overall seemed to show some levels of agreement for certain emotions. Using both descriptive statistics and visual analyses to calculate the differences, an overall comparison of both ai systems showed that the mean emotion scores differ across the two models.
The average difference in the emotion scores showed values indicating that Hume AI obtained higher scores for the emotions anger and fear, while NLP Cloud proved to show higher scores for joy, sadness and surprise. Despite these findings, the score for sadness and surprise were sufficiently low, suggesting that the models were substantially aligned on specifically those emotions.
Joy being highly scored by NLP Cloud indicates that joy may not have been as easily identified in speech-based emotion analysis, while the textual context may have conveyed a more positive tone from the text than appeared in the voice. In contrast, anger and fear appeared to have been more effectively captured by the speech-based emotion detection, possibly suggesting that someone might sound angry or fearful even though they may not be experiencing these emotions in the moment.
Based on the Pearson correlation analysis showing the association between the text-based and speech-based emotion recognitions, the strongest alignments were shown for Joy (r = 0.521) and anger (r = 0.468). Joy and anger also showed statistically significant p-values, where joy had a p-value of 0.0069, and anger had a p-value of 0.0022. No further strong correlations or statistically significant p-values were found in the other emotions.
Several factors may account for this result. For example, joy and anger are distinct emotions, while sadness, fear and surprise may likely involve more subtle cues and contextual factors. Being more complex to detect may have contributed to the lower consistency across the two models for these specific emotions.

For the full dataset, paired t-tests showed no significant differences for the mean score of the emotions across the dataset for all emotions except fear. Although the correlation between Hume AI and NLP Cloud showed non-significant scores for fear, the t-test indicated that while the systems do not align on detecting patterns for fear, Hume AI consistently rates the fear higher than NLP Cloud. Possible explanations for this result may reflect the differences in how emotions are conveyed and detected in the different models, whereas Hume AI possibly could have captured the more subtle vocal indicators that might not have been as easily expressed or detected in text.

Examining the t-tests for the positive oriented interviews in comparison to the negative oriented interviews, notable findings emerged.
For the positive interviews, significant differences between Hume AI and NLP Cloud were found for all emotions with the exception of surprise, where Hume consistently detected higher levels of sadness and fear and NLP on the other hand overestimated joy and anger in comparison to Hume.
This may be explained by the complexity of emotions and emotional expression. In the positive interviews, the participants discussed joyful topics, and while this may have been detected for the text-based emotion recognition, the vocal tone could reveal more subtle cues in the tone, rhythm and pitch. For a positive interview, the participant may have a lower and more neutral tone and pitch than an actor acting out happiness, which could be one explanation for this result.
For the negative interviews, significant differences were only identified for joy and sadness, where Hume rated joy with a higher score, and NLP rated sadness higher. This indicates a better alignment for the different models for the analyses made for the negatively oriented interviews.

Possible explanations for these results are that people participating in the interviews may have used overly positive language out of politeness, even if the content of the words may have been negative.
\subsubsection{Sentiment-Based Analysis RQ2}
In comparing Hume AI and NLP Cloud, the sentiment-based analysis presented a distinct pattern in how the different AI models interpreted the positively oriented interviews versus the negatively oriented interviews, where some emotions were consistently rated higher than others.

NLP Cloud showed patterns of consistently rating joy higher than Hume AI, while Hume rated higher for negative emotions such as anger, sadness and fear in the positive interviews.

These results indicate that the subtle features such as pitch, loudness and more may have been interpreted by Hume as negative emotions even in positive conversations.
Surprise remained a challenging emotion to detect, and NLP Cloud showed higher values of anger and sadness in the negative interviews, likely due to being able to better capture the negative context of the interviews through the text-based analysis.
Hume rated joy unexpectedly high in the negative interviews, where a possible reason could be nervous laughter or other emotions that could have been misclassified.
Overall, the results underscores that the two AI models differ in the job of emotion detection, possibly due to the vocal recordings involving subtly expressed emotions or possible irony or laughter that could have been incorrectly categorized as joy. 
