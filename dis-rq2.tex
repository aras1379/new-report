
\section{Result Discussion RQ2}
For the second research question in this thesis, the aim was to investigate the similarities and differences between the two AI models Hume AI, a speech-based model, and NLP Cloud, a text-based model. This was measured when labelling five different emotions in semi-structured interviews.

\label{subsec:RQ2interpretation}
In the comparison between the speech-based emotion recognition model, Hume AI, and the text-based emotion recognition model NLP Cloud, the system overall seemed to show some levels of agreement for certain emotions. Using both descriptive statistics and visual analyses to calculate the differences, an overall comparison of both ai systems showed that the mean emotion scores differ across the two models.

The average difference in the emotion presented in table~\ref{tab:rq3_emotion-stats-combined} scores for all recordings showed values indicating that Hume AI obtained higher scores for the emotions anger and fear, while NLP Cloud proved to show higher scores for joy, sadness and surprise. Despite these findings, the score for sadness and surprise were sufficiently low, suggesting that the models were substantially aligned on specifically those emotions, although is important to note that this table shows the average for all recordings. Taking the average of both the positive and negative recordings likely resulted in the opposing emotion values suppressing each other, leading to a more neutral score.

In figure~\ref{fig:rq2_sent_grouped_bar}, the results of the entire dataset divided between the positive and negative recordings were presented. These results showed NLP Cloud having a significantly higher mean emotion score for joy and a slightly higher score for surprise in the positive recordings. In the negative recordings, NLP Cloud had a higher score for anger and sadness. 

Hume on the other hand, showed a significantly higher emotion score for anger, and a somewhat higher score for sadness and fear in the positive recordings. For the negative recordings, only joy showed a very significantly higher score compared to NLP Cloud, whereas fear and surprise showed to be somewhat aligned between the two models. Joy being highly scored for Hume AI in the negative recordings may be due to some signals being misinterpreted when speaking of negative topics, for example some participants may have talked about the negative topics in an ironic tone or with sarcasm or expressed nervous laughter, which would be hard for a speech-based model to differentiate and pick up on without the textual context.

Joy being highly scored by NLP Cloud in the positive recordings indicates that joy may not have been as easily identified in speech-based emotion analysis, as the textual context may have conveyed a more positive tone from the text than what appeared in the voice. In contrast, anger and fear appeared to have been more effectively captured by the speech-based emotion detection in the positive clips, possibly suggesting that someone might sound angry or fearful even though they may not be experiencing these emotions in the moment.



Based on the Pearson correlation analysis in table~\ref{tab:corr_all}, showing the association between the text-based and speech-based emotion recognition models for all recordings, the strongest alignments were shown for Joy (r = 0.521) and anger (r = 0.466). Joy and anger also showed statistically significant p-values, where joy had a p-value of 0.002, and anger had a p-value of 0.007. No further strong correlations or statistically significant p-values were found in the other emotions.

Several factors may account for this result. For example, joy and anger are distinct emotions, while sadness, fear and surprise may likely involve more subtle cues and contextual factors. Being more complex to detect may have contributed to the lower consistency across the two models for these specific emotions.

For the positive recordings only, there were two emotion showing significant correlations between the two models, joy (r = 0.160, p = 0.568) and sadness (r = 0.549, 0.035), whereas for the negative recordings the only emotion that showed a significant correlation was joy (r = 0.556, p = 0.020).

These results suggests that joy is the easiest emotion to detect for the models regardless of the context, and that anger, fear and surprise may be too complex to detect, although there are several possible reasons as to why they have low or inconsistent correlations. The way that the interviews are set up and the fact that the participants of the interviews talk about situations and feelings they have lived through in the past, may have resulted in emotions being expressed in a subdued way. Talking about a time where you felt fear or surprise might not be translated as strongly when time has passed, as it would in the moment when the emotions were felt.

With this in mind, the lack of correlations for more complex emotions suggest that the interview format may have been insufficient to draw out more nuanced emotional responses. Alternatively, the AI models used may have some limitations in detecting subtle emotions.


For the full dataset, paired t-tests showed no significant differences for the mean score of the emotions across the dataset for all emotions except fear. Although the correlation between Hume AI and NLP Cloud showed non-significant scores for fear, the t-test indicated that while the systems do not align on detecting patterns for fear, Hume AI consistently rates the fear higher than NLP Cloud. Possible explanations for this result may reflect the differences in how emotions are conveyed and detected in the different models, whereas Hume AI possibly could have captured the more subtle vocal indicators that might not have been as easily expressed or detected in text.

In examining the t-tests for the positive oriented interviews in comparison to the negative oriented interviews, notable findings emerged.

For the positive interviews, significant differences between Hume AI and NLP Cloud were found for all emotions with the exception of surprise, where Hume consistently detected higher levels of anger, sadness and fear. NLP on the other hand overestimated joy significantly in comparison to Hume. 
This may be explained by the complexity of emotions and emotional expression. In the positive interviews, the participants discussed joyful topics, and while this may have been detected for the text-based emotion recognition, the vocal tone could reveal more subtle cues in the tone, rhythm and pitch. For the positive interviews, the participants may have had a lower and more neutral tone and pitch than an actor acting out happiness, which could be one explanation for this result.

For the negative interviews, significant differences were only identified for joy and sadness, where Hume rated joy with a higher score, and NLP rated sadness higher. This indicates a better alignment for the different models for the analyses made for the negatively oriented interviews.

Possible explanations for these results are that people participating in the interviews may have used overly positive language out of politeness, even if the content of the words may have been negative, which would explain why Hume AI detected joy from negative oriented interviews.
