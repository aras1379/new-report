\section{Limitations}

\subsection{Limitations RQ1}
There are several limitations which should be taken into consideration when interpreting the results presented for the first research question.

Firstly, the dataset conducted and used for this study consist of spontaneous conversational semi-structured interviews. This likely has resulted in more subtle emotions than an acted dataset would contain with weaker emotional expressions reducing the detectability of different vocal markers. 
This study has also been restricted to a small set of acoustic features for the analysis. There are possibilities other acoustic features would have contributed with relevant aspects for the analyses if included. This study does not involve all vocal features that are included in the research by Ekberg \autocite{Ekberg2023} which potentially could have shown relevant information and possible alignments, however, due to the timeframe and scope of this study only five vocal markers were chosen.

Another important limitation to consider is the static averages of the vocal features. Despite effort where some clips have been visualized in its entirety, showing spikes in one specific emotion combined with one specific vocal feature from time to time, most clips involved in the process of answering the first research question are the result of an average per clip. This may have obscured some dynamic fluctuations of all emotions over time.

A further constraint worth noting is that the Hume AI emotion scores are not perfect estimates of true emotional states themselves and should not be considered ground truth in this study, only a way of comparison and finding potential similarities. Additionally, although Hume showed varied and appropriate emotion outputs, it is important to note that the Hume AI emotion outputs are based on soft scoring. This often produces mixed emotions rather than single emotional states, making comparisons more difficult.

Finally, the usage of the Swedish vocal data collected from semi-structured interviews. These interviews consist of spontaneous and conversational speech which likely do not involve as strong emotional expressions as acted datasets. Conversational speech tends to be more subtle and may have a reduced level of clear vocal markers. 

Worth noting is that the interviews conducted for this study were context-dependent and influenced by topics selected by the participants of the interviews themselves, introducing potential additional variability from interview to interview. Contrary, the Swedish research by Ekberg consisted of 14 repeated sentences.

\subsection{Limitations RQ2 and RQ3}
This study has presented several important insights in emotion detection using AI models, although there are several limitations that should be noted.
The spontaneous nature of the interviews remains a limitation through RQ2 and RQ3, as these vocal recordings may have given more subtle and muted emotional expressions compared to an acted dataset would. The calm setting of the interviews may also be an explanation to why fear and surprise especially was not detected to a high degree.

The self-reported emotions unavoidably involve subjective biases, which possibly could have resulted in some variety across interviews. 
The dataset size and the limited emotions remains a limitation, where a larger dataset and more emotions possibly could lead to broader findings and correlations.
