@article{Safari2023,
   author = {F Safari and A Chalechale},
   doi = {https://doi.org/10.1007/s10462-023-10603-3},
   issue = {Suppl 3},
   journal = {The Artificial intelligence review},
   pages = {3273-3297},
   title = {Emotion and personality analysis and detection using natural language processing, advances, challenges and future scope},
   volume = {56},
   year = {2023}
}
@inbook{Kansara2020,
   author = {D Kansara and V Sawant and N Shekokar and H Vasudevan and M Narvekar and A. Michalas},
   doi = {https://doi.org/10.1007/978-981-15-3242-9_35},
   booktitle = {Advanced Computing Technologies and Applications},
   pages = {365-377},
   publisher = {Springer},
   title = {Comparison of Traditional Machine Learning and Deep Learning Approaches for Sentiment Analysis},
   year = {2020}
}
@article{Alvarez2024,
   author = {A Álvarez Núñez and M. del C Santiago Díaz and A. C Zenteno Vázquez and J Pérez Marcial and G. T Rubín Linares},
   doi = {https://doi.org/10.61467/2007.1558.2024.v15i5.564},
   issue = {5},
   journal = {International Journal of Combinatorial Optimization Problems and Informatics},
   pages = {108-114},
   title = {Emotion detection using natural language processing},
   volume = {15},
   year = {2024}
}
@article{Madhuri2021,
   author = {S Madhuri and V Lakshmi},
   issue = {10},
   journal = {Turkish journal of computer and mathematics education},
   pages = {4095-4103},
   title = {Detecting Emotion from Natural Language Text Using Hybrid and NLP Pre-trained Models},
   volume = {12},
   year = {2021}
}
@article{Ermakova2023,
   author = {T Ermakova and B Fabian and E Golimblevskaia and M Henke},
   doi = {https://doi.org/10.1007/s42979-023-01886-y},
   issue = {5},
   journal = {SN computer science},
   pages = {477--},
   title = {A Comparison of Commercial Sentiment Analysis Services},
   volume = {4},
   year = {2023}
}
@article{Zhang2018,
   author = {L Zhang and S Wang and B. Liu},
   doi = {https://doi.org/10.1002/widm.1253},
   issue = {4},
   journal = {Data mining and knowledge discovery},
   pages = {1253-n/a},
   title = {Deep learning for sentiment analysis: A survey},
   volume = {8},
   year = {2018}
}
@inbook{Ahammed2024,
   author = {M Ahammed and R Sheikh and F Hossain and S. M Liza and M. A Rahman and M Mahmud and D. J Brown and M. R Ahmed and H Ben-Abdallah and M. S Kaiser and N Zhong},
   city = {Switzerland},
   doi = {https://doi.org/10.1007/978-3-031-68639-9_3},
   booktitle = {Applied Intelligence and Informatics},
   pages = {32-46},
   publisher = {Springer},
   title = {Speech Emotion Recognition: An Empirical Analysis of Machine Learning Algorithms Across Diverse Data Sets},
   year = {2024}
}
@book{Oatley2019,
   author = {K Oatley and D Keltner and J. M Jenkins},
   publisher = {Blackwell},
   title = {Understanding emotions Fourth Edition},
   year = {2019}
}
@article{Kusal2023,
   author = {S Kusal and S Patil and J Choudrie and K Kotecha and D Vora and I Pappas},
   doi = {https://doi.org/10.1007/s10462-023-10509-0},
   issue = {12},
   journal = {The Artificial intelligence review},
   pages = {15129-15215},
   title = {A systematic review of applications of natural language processing and future challenges with special emphasis in text-based emotion detection},
   volume = {56},
   year = {2023}
}
@article{Ekman2016,
   author = {P Ekman},
   doi = {https://doi.org/10.1177/1745691615596992},
   issue = {1},
   journal = {Perspectives on psychological science},
   pages = {31-34},
   title = {What Scientists Who Study Emotion Agree About},
   volume = {11},
   year = {2016}
}
@article{Kusal2024,
   author = {S. D Kusal and S. G Patil and J Choudrie and K. V. Kotecha},
   doi = {https://doi.org/10.1145/3643133},
   issue = {8},
   journal = {ACM transactions on Asian and low-resource language information processing},
   pages = {1-26},
   title = {Understanding the Performance of AI Algorithms in Text-Based Emotion Detection for Conversational Agents},
   volume = {23},
   year = {2024}
}
@article{Khalil2019,
   author = {R. A Khalil and E Jones and M. I Babar and T Jan and M. H Zafar and T Alhussain},
   doi = {https://doi.org/10.1109/ACCESS.2019.2936124},
   journal = {IEEE access},
   pages = {117327-117345},
   title = {Speech Emotion Recognition Using Deep Learning Techniques: A Review},
   volume = {7},
   year = {2019}
}
@article{Sahoo2023,
   author = {C Sahoo and M Wankhade and B. K Singh},
   doi = {https://doi.org/10.1007/s13735-023-00308-2},
   issue = {2},
   journal = {International journal of multimedia information retrieval},
   pages = {41--},
   title = {Sentiment analysis using deep learning techniques: a comprehensive review},
   volume = {12},
   year = {2023}
}
@article{Jadoul2018,
   author = {Y Jadoul and B Thompson and B. de Boer},
   doi = {https://doi.org/10.1016/j.wocn.2018.07.001},
   journal = {Journal of phonetics},
   pages = {1-15},
   title = {Introducing Parselmouth: A Python interface to Praat},
   volume = {71},
   year = {2018}
}
@book{Tian2022,
   author = {L Tian and S Oviatt and M Muszyński and B. C Chamberlain and J Healey and A Sano},
   city = {New York City},
   publisher = {Association for Computing Machinery},
   title = {Applied Affective Computing},
   year = {2022}
}
@article{Ekman2011,
   author = {P Ekman and D Cordaro},
   doi = {https://doi.org/10.1177/1754073911410740},
   issue = {4},
   journal = {Emotion Review},
   pages = {364-370},
   title = {What is Meant by Calling Emotions Basic},
   volume = {3},
   year = {2011}
}
@article{Tyagi2024,
   author = {S Tyagi and S Szénási},
   doi = {https://doi.org/10.1007/s11042-023-17769-6},
   issue = {29},
   journal = {Multimedia tools and applications},
   pages = {73427-73456},
   title = {Semantic speech analysis using machine learning and deep learning techniques: a comprehensive review},
   volume = {83},
   year = {2024}
}
@book{Scherer2018,
   author = {K. R Scherer and S Frühholz and P Belin},
   city = {Oxford},
   doi = {10.1093/oxfordhb/9780198743187.013.4},
   publisher = {Oxford University Press},
   title = {Acoustic Patterning of Emotion Vocalizations},
   year = {2018}
}
@inbook{Thaler2024,
   author = {F Thaler and M Haug and H Gewald and P Brune and F Pennarola and J Pallud and A. M Braccini},
   city = {Cham},
   doi = {https://doi.org/10.1007/978-3-031-52120-1_8},
   booktitle = {Technologies for Digital Transformation},
   pages = {129-143},
   publisher = {Springer Nature Switzerland},
   title = {The Context Sets the Tone: A Literature Review on Emotion Recognition from Speech Using AI},
   volume = {64},
   year = {2024}
}
@article{Jadoul2024,
   author = {Y Jadoul and B de Boer and A. Ravignani},
   doi = {https://doi.org/10.1080/09524622.2023.2259327},
   issue = {1},
   journal = {Bioacoustics Berkhamsted},
   pages = {1-19},
   title = {Parselmouth for bioacoustics: automated acoustic analysis in Python},
   volume = {33},
   year = {2024}
}
@article{Juslin2018,
   author = {P. N Juslin and P. Laukka and T Bänziger},
   doi = {https://doi.org/10.1007/s10919-017-0268-x},
   issue = {1},
   journal = {Journal of nonverbal behavior},
   pages = {1-40},
   title = {The Mirror to Our Soul? Comparisons of Spontaneous and Posed Vocal Expression of Emotion},
   volume = {42},
   year = {2018}
}
@article{Rathi2024,
   author = {T Rathi and M. Tripathy},
   doi = {https://doi.org/10.1016/j.specom.2024.103102},
   journal = {Speech communication},
   pages = {103102--},
   title = {Analyzing the influence of different speech data corpora and speech features on speech emotion recognition: A review},
   volume = {162},
   year = {2024}
}
@article{Jahangir2022,
   author = {R Jahangir and Y. W Teh and G Mujtaba and R Alroobaea and Z. H Shaikh and I Ali},
   doi = {10.1007/s00138-022-01294-x.},
   issue = {3},
   journal = {Machine vision and applications},
   title = {Convolutional neural network-based cross-corpus speech emotion recognition with data augmentation and features fusion},
   volume = {33},
   year = {2022}
}
@article{Zhao2019,
   author = {J Zhao and X Mao and L. Chen},
   doi = {https://doi.org/10.1016/j.bspc.2018.08.035},
   journal = {Biomedical signal processing and control},
   pages = {312-323},
   title = {Speech emotion recognition using deep 1D \& 2D CNN LSTM networks},
   volume = {47},
   year = {2019}
}
@misc{Cai2023,
   author = {Y Cai and X Li and J Li},
   city = {Basel, Switzerland},
   doi = {https://doi.org/10.3390/s23052455},
   issue = {5},
   pages = {2455--},
   title = {Emotion Recognition Using Different Sensors, Emotion Models, Methods and Datasets: A Comprehensive Review. Sensors},
   volume = {23},
   year = {2023}
}
@misc{StevenRLivingstone2019,
   author = {Steven R. Livingstone and Frank A. Russo.},
   doi = {10.34740/KAGGLE/DSV/256618},
   publisher = {KAGGLE},
   title = {RAVDESS Emotional speech audio dataset},
   url = {https://doi.org/10.34740/KAGGLE/DSV/256618},
   year = {2019}
}
@misc{Pichora-Fuller2020,
   author = {M. Kathleen Pichora-Fuller and Kate Dupuis},
   doi = {https://doi.org/10.5683/SP2/E8H2MF},
   publisher = {Borealis},
   title = {Toronto emotional speech set (TESS)},
   year = {2020}
}
@misc{kaggle-savee,

   author = {University of Surrey},
   publisher = {KAGGLE},
   title = {Surrey Audio-Visual Expressed Emotion (SAVEE)},
   url = {https://www.kaggle.com/datasets/ejlok1/surrey-audiovisual-expressed-emotion-savee}
}
@article{Alroobaea2024,
   author = {R Alroobaea},
   doi = {https://doi.org/10.1016/j.compbiomed.2024.108841},
   journal = {Computers in biology and medicine},
   pages = {108841},
   title = {Cross-corpus speech emotion recognition with transformers: Leveraging handcrafted features and data augmentation},
   volume = {179},
   year = {2024}
}
@article{Praseetha2022,
   author = {V. M Praseetha and P. P Joby},
   doi = {https://doi.org/10.1007/s10772-021-09883-3},
   issue = {4},
   journal = {International journal of speech technology},
   pages = {783-792},
   title = {Speech emotion recognition using data augmentation},
   volume = {25},
   year = {2022}
}
@article{Zhang2021,
   author = {S Zhang and X Tao and Y Chuang and X Zhao},
   doi = {https://doi.org/10.1016/j.specom.2020.12.009},
   journal = {Speech communication},
   pages = {73-81},
   title = {Learning deep multimodal affective features for spontaneous speech emotion recognition},
   volume = {127},
   year = {2021}
}
@article{Brooks2023,
   author = {J. A Brooks and P Tzirakis and A Baird and L Kim and M Opara and X Fang and D Keltner and M Monroy and R Corona and J Metrick and A. S Cowen},
   doi = {https://doi.org/10.1038/s41562-022-01489-2},
   issue = {2},
   journal = {Nature human behaviour},
   pages = {240-250},
   title = {Deep learning reveals what vocal bursts express in different cultures},
   volume = {7},
   year = {2023}
}
@inproceedings{Baird2022,
   author = {A Baird and P Tzirakis and J. A Brooks and C. B Gregory and B Schuller and A Batliner and D Keltner and A Cowen},
   city = {Nara, Japan},
   doi = {https://doi.org/10.1109/ACIIW57231.2022.10086002},
   booktitle = {10th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos ACIIW},
   pages = {1-5},
   title = {The ACII 2022 Affective Vocal Bursts Workshop \&  Competition},
   year = {2022}
}
@article{Cowen2019,
   author = {A. S Cowen and P Laukka and H. A Elfenbein and R Liu and D. Keltner},
   doi = {https://doi.org/10.1038/s41562-019-0533-6},
   issue = {4},
   journal = {Nature human behaviour},
   pages = {369-382},
   title = {The primacy of categories in the recognition of 12 emotions in speech prosody across two cultures},
   volume = {3},
   year = {2019}
}
@article{Thompson2004,
   author = {W. F Thompson and E. G Schellenberg and G Husain},
   doi = {https://doi.org/10.1037/1528-3542.4.1.46},
   issue = {1},
   journal = {Emotion},
   pages = {46-64},
   title = {Decoding speech prosody: Do music lessons help?},
   volume = {4},
   year = {2004}
}
@article{Tomasello2022,
   author = {R Tomasello and L Grisoni and I Boux and D Sammler and F Pulvermüller},
   city = {New York, N.Y},
   doi = {https://doi.org/10.1093/cercor/bhab522},
   issue = {21},
   journal = {Cerebral cortex},
   pages = {4885-4901},
   title = {Instantaneous neural processing of communicative functions conveyed by speech prosody},
   volume = {32},
   year = {2022}
}
@misc{HumeAi-aboutScience,
   author = {AI Hume},
   title = {About the Science},
   url = {https://dev.hume.ai/docs/resources/science}
}
@misc{HumeAI-AboutHume,
   author = {AI Hume},
   title = {About Hume},
   url = {https://www.hume.ai/about}
}
@article{Ning2025,
   author = {J Ning and W. Zhang},
   doi = {https://doi.org/10.1007/s11760-024-03574-7},
   issue = {2},
   journal = {Signal, image and video processing},
   title = {Speech-based emotion recognition using a hybrid RNN-CNN network},
   volume = {19},
   year = {2025}
}
@article{LGENSNMEZ2024,
   author = {Y Ülgen Sönmez and A Varol},
   doi = {https://doi.org/10.1016/j.iswa.2024.200351},
   issue = {22},
   journal = {Intelligent systems with applications},
   pages = {200351--},
   title = {In-depth investigation of speech emotion recognition studies from past to present. The importance of emotion recognition from speech signal for AI},
   year = {2024}
}
@article{Bnziger2014,
   author = {T Bänziger and S Patel and K. R. Scherer},
   doi = {https://doi.org/10.1007/s10919-013-0165-x},
   issue = {1},
   journal = {Journal of nonverbal behavior},
   pages = {31-52},
   title = {The Role of Perceived Voice and Speech Characteristics in Vocal Emotion Communication},
   volume = {38},
   year = {2014}
}
@article{ChulMinLee2005,
   author = {Chul Min Lee and S. S Narayanan},
   doi = {https://doi.org/10.1109/TSA.2004.838534},
   issue = {2},
   journal = {IEEE transactions on speech and audio processing},
   pages = {293-303},
   title = {Toward detecting emotions in spoken dialogs},
   volume = {13},
   year = {2005}
}
@article{Ri2023,
   author = {F. A. D Ri and F. C Ciardi and N Conci},
   doi = {https://doi.org/10.1109/ACCESS.2023.3326071},
   journal = {IEEE Access},
   pages = {1},
   title = {Speech Emotion Recognition and Deep Learning: an Extensive Validation using Convolutional Neural Networks},
   volume = {11},
   year = {2023}
}
@article{Lian2023,
   author = {H Lian and C Lu and S Li and Y Zhao and C Tang and Y Zong},
   city = {Entropy Basel, Switzerland},
   doi = {https://doi.org/10.3390/e25101440},
   journal= {Entropy (Basel, Switzerland)},
   issue = {10},
   pages = {1440--},
   title = {A Survey of Deep Learning-Based Multimodal Emotion Recognition: Speech, Text, and Face},
   volume = {25},
   year = {2023}
}
@article{Adebiyi2024,
   author = {M. O Adebiyi and T. T Adeliyi and D Olaniyan and J. Olaniyan},
   doi = {https://doi.org/10.12928/TELKOMNIKA.v22i3.25708},
   issue = {3},
   journal = {Telkomnika},
   pages = {606-618},
   title = {Advancements in accurate speech emotion recognition through the integration of CNN-AM model},
   volume = {22},
   year = {2024}
}
@inproceedings{Rahman2024,
   author = {Md. M Rahman and Md. A Hossain and T. Hasan and Md. K Ahmed and R Sultana and M. S Islam},
   doi = {https://doi.org/10.1109/ICEEICT62016.2024.10534404},
   booktitle = {2024 6th International Conference on Electrical Engineering and Information \&  Communication Technology ICEEICT},
   pages = {592-597},
   publisher = {IEEE},
   title = {EmotionNet: Pioneering Deep Learning Fusion for Real-Time Speech Emotion Recognition with Convolutional Neural Networks},
   year = {2024}
}
@article{Abbaschian2021,
   author = {B. J Abbaschian and D Sierra-Sosa and A. Elmaghraby},
   city = {Basel, Switzerland},
   doi = {https://doi.org/10.3390/s21041249},
journal = {Sensors Basel, Switzerland},
   issue = {4},
   pages = {1-27},
   title = {Deep Learning Techniques for Speech Emotion Recognition, from Databases to Models},
   volume = {21},
   year = {2021}
}
@article{DeSouza2021,
   author = {D. D DeSouza and J Robin and M Gumus and A Yeung},
   doi = {https://doi.org/10.3389/fpsyt.2021.719125},
   journal = {Frontiers in psychiatry},
   pages = {719125},
   title = {Natural Language Processing as an Emerging Tool to Detect Late-Life Depression},
   volume = {12},
   year = {2021}
}
@article{Drougkas2024,
   author = {G Drougkas and E. M Bakker and M Spruit},
   doi = {https://doi.org/10.1186/s12911-024-02772-0},
   issue = {1},
   journal = {BMC medical informatics and decision making},
   pages = {320-354},
   title = {Multimodal machine learning for language and speech markers identification in mental health},
   volume = {24},
   year = {2024}
}
@article{Pandey2023,
   author = {S. K Pandey and H. S Shekhawat and S. R. M Prasanna},
   doi = {https://doi.org/10.1016/j.bspc.2023.104679},
   journal = {Biomedical signal processing and control},
   pages = {104679--},
   title = {Multi-cultural speech emotion recognition using language and speaker cues},
   volume = {83},
   year = {2023}
}
@article{Maruf2024,
   author = {A. A Maruf and F Khanam and Md. M Haque and Z. M Jiyad and M. F Mridha and Z Aung},
   doi = {https://doi.org/10.1109/ACCESS.2024.3356357},
   journal = {IEEE access},
   pages = {18416-18450},
   title = {Challenges and Opportunities of Text-Based Emotion Detection: A Survey},
   volume = {12},
   year = {2024}
}
@inbook{Milner2019,
   author = {R Milner and M. A Jalal and R. W. M Ng and T Hain},
   doi = {https://doi.org/10.1109/ASRU46091.2019.9003838},
   booktitle = {IEEE Automatic Speech Recognition and Understanding Workshop ASRU},
publisher = {IEEE}, 
   pages = {304-311},
   title = {A Cross-Corpus Study on Speech Emotion Recognition},
   year = {2019}
}
@article{Ekberg2023,
   author = {M Ekberg and G Stavrinos and J Andin and S Stenfelt and Ö. Dahlström},
   doi = {10.1016/j.jvoice.2023.03.010.},
   journal = {Journal of voice},
   title = {Acoustic Features Distinguishing Emotions in Swedish Speech},
   year = {2023}
}

@article{Montasem2013,
   author = {A Montasem and S. L Brown and R Harris},
   issue = {5},
   journal = {Journal of Applied Social Psychology},
   pages = {1097-1103},
   title = {Do core self-evaluations and trait emotional intelligence predict subjective well-being in dental students?},
   volume = {43},
   url = {https://doi.org/10.1111/jasp.12074},
   year = {2013}
}
@misc{HumeAIProsody,
   author = {Hume AI},
   title = {Prosody},
   url = {https://www.hume.ai/products/speech-prosody-model}
}
@misc{HumeAIVocalExpression,
   author = {Hume AI},
   title = {Vocal Expression},
   url = {https://www.hume.ai/products/vocal-expression-model}
}
@article{Siedlecka2019,
   author = {E Siedlecka and T. F Denson},
   doi = {https://doi.org/10.1177/1754073917749016},
   issue = {1},
   journal = {Emotion Review},
   pages = {87-97},
   title = {Experimental Methods for Inducing Basic Emotions: A Qualitative Review},
   volume = {11},
   year = {2019}
}
@article{Lee2023,
   author = {S. J Lee and J Lim and L Paas and H. S Ahn},
   doi = {https://doi.org/10.1007/s00521-023-08276-8},
   issue = {15},
   journal = {Neural computing \&  applications},
   pages = {10945-10956},
   title = {Transformer transfer learning emotion detection model: synchronizing socially agreed and self-reported emotions in big data},
   volume = {35},
   year = {2023}
}
@book{Frhholz2019,
   author = {S Frühholz and P Belin},
   city = {Oxford},
   publisher = {Oxford University Press},
   title = {The Oxford handbook of voice perception},
   year = {2019}
}
@book{Creswell2023,
   author = {J. W Creswell and J. D Creswell},
   city = {Los Angeles},
   edition = {Fifth},
   publisher = {SAGE},
   title = {Research design : qualitative, quantitative, and mixed methods approaches},
   year = {2023}
}
@book{Bryman2022,
   author = {A Bryman and E Bell and J Reck and J Fields},
   publisher = {Oxford University Press},
   title = {Social Research Methods},
   year = {2022}
}
@misc{OpenAI2022,
   author = {OpenAI},
   month = {9},
   title = {Introducing Whisper},
   url = {https://openai.com/index/whisper/},
   year = {2022}
}
@inproceedings{Babu2021,
   author = {P. A Babu and V Siva Nagaraju and R. R Vallabhuni},
   city = {Bhopal, India},
   doi = {https://doi.org/10.1109/CSNT51715.2021.9509714},
   booktitle = {10th IEEE International Conference on Communication Systems and Network Technologies CSNT},
   pages = {421-424},
   title = {Speech Emotion Recognition System With Librosa},
   year = {2021}
}
@article{Esfahani2024,
   author = {S. H. N Esfahani and M. Adda},
   doi = {https://doi.org/10.1016/j.procs.2024.08.013},
   journal = {Procedia Computer Science},
   pages = {77-84},
   title = {Classical Machine Learning and Large Models for Text-Based Emotion Recognition},
   volume = {241},
   year = {2024}
}
@article{Shelke2022,
   author = {N Shelke and S Chaudhury and S Chakrabarti and S. L Bangare and G Yogapriya and P. Pandey},
   doi = {https://doi.org/10.1016/j.neuri.2022.100048},
   issue = {3},
   journal = {Neuroscience informatics},
   pages = {100048},
   title = {An efficient way of text-based emotion analysis from social media using LRA-DNN},
   volume = {2},
   year = {2022}
}
@misc{NLPCloud,
   author = {NLP Cloud},
   title = {Advanced AI Platform},
   url = {https://nlpcloud.com/}
}
@misc{VernAI,
   author = {VERN AI},
   title = {VERN},
   url = {https://vernai.com/}
}
@misc{TwinWord,
   author = {TwinWord},
   title = {Just The Best Keywords},
   url = {https://www.twinword.com/ideas/}
}
@article{Radford2022,
   author = {A Radford and J. W Kim and T Xu and G Brockman and C McLeavey and I Sutskever},
   doi = {https://doi.org/10.48550/arxiv.2212.04356},
   journal = {Robust Speech Recognition via Large-Scale Weak Supervision},
   title = {Robust Speech Recognition via Large-Scale Weak Supervision},
   year = {2022}
}
@article{Areshey2024,
   author = {A Areshey and H Mathkour},
   doi = {https://doi.org/10.1111/exsy.13701},
   issue = {11},
   journal = {Expert systems},
   title = {Exploring transformer models for sentiment classification: A comparison of BERT, RoBERTa, ALBERT, DistilBERT, and XLNet},
   volume = {41},
   year = {2024}
}
@inproceedings{Zhang2024,
   author = {J Zhang and Z M},
   city = {New York},
   doi = {https://doi.org/10.1145/3696271.3696292},
   booktitle = {Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence MLMI},
   pages = {128-132},
   title = {Is LLaMA 3 Good at Identifying Emotion? A Comprehensive Study},
   year = {2024}
}
@article{Kumar2024,
   author = {S Kumar and S Singh},
   doi = {https://doi.org/10.1007/s42979-024-03473-1},
   issue = {8},
   journal = {SN computer science},
   pages = {1161},
   title = {Fine-Tuning Llama 3 for Sentiment Analysis: Leveraging AWS Cloud for Enhanced Performance},
   volume = {5},
   year = {2024}
}
@article{SilvaBarbon2022,
   author = {R Silva Barbon and A. T Akabane},
   city = {Basel, Switzerland},
   doi = {https://doi.org/10.3390/s22218184},
   issue = {21},
   journal = {Sensors (Basel, Switzerland)},
   pages = {8184},
   publisher = {Sensors},
   title = {Towards Transfer Learning Techniques—BERT, DistilBERT, BERTimbau, and DistilBERTimbau for Automatic Text Classification from Different Languages: A Case Study},
   volume = {22},
   year = {2022}
}
@article{Repede2024,
   author = {S. E Repede and R Brad},
   doi = {https://doi.org/10.3390/computers13110292},
   issue = {11},
   journal = {Computers (Basel)},
   pages = {292},
   title = {LLaMA 3 vs. State-of-the-Art Large Language Models: Performance in Detecting Nuanced Fake News},
   volume = {13},
   year = {2024}
}
@misc{Auphonic,
   author = {Auphonic},
   title = {Features},
   url = {https://auphonic.com/features}
}
@misc{HappyPlanetIndex,
   author = {HappyPlanetIndex},
   journal = {https://happyplanetindex.org/learn-about-the-happy-planet-index/},
   title = {What is the Happy Planet Index?},
   url = {https://happyplanetindex.org/learn-about-the-happy-planet-index/}
}
@article{Demszky2020,
   author = {D Demszky and Movshovitz-Attias D and J Ko and A Cowen and G Nemade and S. Ravi},
   doi = {https://doi.org/10.48550/arxiv.2005.00547},
   journal = {Proceedings of the 58th Annual Meeting of the Association for Computional Linguistics},
   pages = {4040-4054},
   publisher = {Online},
   title = {GoEmotions: A Dataset of Fine-Grained Emotions},
   year = {2020}
}
@article{Singh2023,
   author = {Sonali Singh},
   doi = {10.26483/ijarcs.v14i3.6975},
   issn = {09765697},
   issue = {03},
   journal = {International Journal of Advanced Research in Computer Science},
   month = {6},
   pages = {87-107},
   title = {EMOTION RECOGNITION FOR MENTAL HEALTH PREDICTION USING AI TECHNIQUES: AN OVERVIEW},
   volume = {14},
   year = {2023}
}

@article{Simcock2020,
   author = {Gabrielle Simcock and Larisa T. McLoughlin and Tamara De Regt and Kathryn M. Broadhouse and Denise Beaudequin and Jim Lagopoulos and Daniel F. Hermens},
   doi = {10.3390/ijerph17010330},
   issn = {1660-4601},
   issue = {1},
   journal = {International Journal of Environmental Research and Public Health},
   month = {1},
   pages = {330},
   title = {Associations between Facial Emotion Recognition and Mental Health in Early Adolescence},
   volume = {17},
   year = {2020}
}
@book{Bruce2017,
   author = {P Bruce and A Bruce},
   publisher = {O'Reilly},
   title = {Practical Statistics for Data Scientists},
   year = {2017}
}

@book{Cohen1977,
   author = {J Cohen},
   publisher = {Academic Press},
   title= {Statistical power analysis for the behavioral sciences (Revised edition)},
   year = {1977}
}

%%%
%%% BIBLIOGRAPHY ENTRIES
%%%

@article{Scherer2003,
   author = {K Scherer},
   doi = {10.1016/S0167-6393-02-00084-5},
   issn = {01676393},
   issue = {1-2},
   journal = {Speech Communication},
   month = {4},
   pages = {227-256},
   title = {Vocal communication of emotion: A review of research paradigms},
   volume = {40},
   year = {2003}
}
@article{Kamilolu2020,
   author = {Roza G. Kamiloğlu and Agneta H. Fischer and Disa A. Sauter},
   doi = {10.3758/s13423-019-01701-x},
   issn = {1069-9384},
   issue = {2},
   journal = {Psychonomic Bulletin and Review},
   month = {4},
   pages = {237-265},
   title = {Good vibrations: A review of vocal expressions of positive emotions},
   volume = {27},
   year = {2020}
}
@article{Banse1996,
   author = {Rainer Banse and Klaus R. Scherer},
   doi = {10.1037/0022-3514.70.3.614},
   issn = {1939-1315},
   issue = {3},
   journal = {Journal of Personality and Social Psychology},
   pages = {614-636},
   title = {Acoustic profiles in vocal emotion expression.},
   volume = {70},
   year = {1996}
}
@article{Cao2015,
   author = {H. Cao and R. Verma and A. Nenkova},
   doi = {10.1016/j.csl.2014.01.003},
   issn = {0885-2308},
   issue = {1},
   journal = {Computer Speech \& Language},
   month = {1},
   pages = {186-202},
   title = {Speaker-sensitive emotion recognition via ranking: Studies on acted and spontaneous speech},
   volume = {29},
   year = {2015}
}
@inproceedings{Chakraborty2016,
   author = {R Chakraborty and M Pandharipande and S K Kopparapu},
   city = {Cancun},
   doi = {https://doi.org/10.1109/ICPR.2016.7900071},
   booktitle = {Proceedings of the 2016 23rd International Conference on Pattern Recognition (ICPR)},
   pages = {2866-2871},
   title = {Spontaneous speech emotion recognition using prior knowledge},
   year = {2016}
}
@article{Chauhan2024,
   author = {K Chauhan and K K Sharma and T Varma},
   doi = {10.1007/s13369-023-08395-3},
   issn = {2191-4281},
   issue = {9},
   journal = {Arabian Journal for Science and Engineering (2011)},
   pages = {11871-11881},
   title = {Multimodal Emotion Recognition Using Contextualized Audio Information and Ground Transcripts on Multiple Datasets},
   volume = {49},
   year = {2024}
}
@article{Soleymani2017,
   author = {M Soleymani and D Garcia and B Jou and B Schuller and S-F Chang and M Pantic},
   doi = {10.1016/j.imavis.2017.08.003},
   issn = {0262-8856},
   issue = {November},
   journal = {Image and Vision Computing},
   pages = {3-14},
   title = {A survey of multimodal sentiment analysis},
   volume = {65},
   year = {2017}
}
@article{Qazi2025,
   author = {A Qazi and R H Goudar and R Patil and G S Hukkeri and D Kulkarni},
   doi = {10.1109/ACCESS.2025.3563301},
   journal = {IEEE Access},
   volume = {13},
   pages = {72918--72929},
   title = {Leveraging BERT, DistilBERT, and TinyBERT for Rumor Detection},
   year = {2025}
}
