\section{Summary of Key Findings and Answering Research Questions}
\label{sec:con-key-findings}
Based on the findings presented in chapter~\ref{sec:results}, the following key findings and answers to the research questions were found.

In the first research question, the aim was to compare the vocal features from speech recordings gathered from interviews to see whether or not they correlate with AI-based emotion detection from the model Hume AI. Existing research on vocal markers in Swedish speech was used for better comparison.
Here, the results showed some alignments between AI-based emotion recognition models with the existing research on vocal markers in Swedish language. Many correlations were weak or moderate and the results showed some limitations, for example. the nature of spontaneous speech involved in interviews presented challenges for some of the emotions, while other emotions proved to be more relevant indicators of emotional states. The results revealed that Hume AI showed promise with the contextual awareness and the flexibility of the model. 
In this research question, important insight was also given through the segment level analyses which presented the fluctuations in the emotions better than average clip analyses.

For the second research question this study explored differences, similarities and correlations between speech-based emotion recognition through Hume AI and text-based emotion recognition through NLP Cloud.
For some emotions more than others, some agreements were found between the models. Joy and anger showed better alignment whereas fear and surprise did not align as much. The overall cause for this most likely being the complex nature of some emotions where the vocal cues may not be as pronounced. 

For the third and last research question, the comparisons between the models Hume AI and NLP Cloud in combination with self-assessed emotion scores from the interviews were investigated. These results showed there were some alignments between the models and self-assessed scores, though these alignments were stronger with NLP Cloud than with Hume AI. This gave insight into the fact that although some alignments were stronger with NLP Cloud than others, a multimodal approach that integrates several sources results in better detection of emotions, where only relying on either a speech-based model or a text-based model would not give as much insight in the results.
Overall, the findings in this research provided answers to all research questions, contributing to a deeper understanding of emotion recognition in the Swedish language and highlighting that the different modalities capture different aspects of emotional expressions.
